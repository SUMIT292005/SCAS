# -*- coding: utf-8 -*-
"""Crop_Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12FkePlBQCdQyZxkIbjmWOAoGyx5P9YDH
"""

# Step 1: Upload your original dataset
from google.colab import files
uploaded = files.upload()  # Upload "crop_and_fertilizer_western_maharashtra.csv"

# Step 2: Load the data
import pandas as pd
df = pd.read_csv('Crop and fertilizer dataset.csv')  # Change filename if needed

# Step 3: Define average humidity values (in %), by crop
humidity_mapping = {
    'rice': 80,
    'maize': 70,
    'cotton': 65,
    'wheat': 60,
    'jowar': 55,
    'bajra': 50,
    'groundnut': 60,
    'gram': 55,
    'ragi': 60,
    'sugarcane': 85,
    'sunflower': 50,
    'tur': 55,
    'urad': 55,
    'matki': 55,
    'moong': 60,
    'lentil': 60,
    'pomegranate': 65,
    'banana': 85,
    'mango': 75,
    'grapes': 70,
    'soybean': 70,
    'orange': 70,
    'papaya': 80
}

# Step 4: Add the humidity column
df['humidity'] = df['Crop'].str.lower().map(humidity_mapping).fillna(60)  # Default to 60 if missing

# Step 5: Save and download the updated CSV
output_csv = 'crop_and_fertilizer_western_maharashtra_filled_humidity.csv'
df.to_csv(output_csv, index=False)

files.download(output_csv)  # Download the completed file

import pandas as pd
from google.colab import files

# Upload both CSVs: Crop_recommendation.csv and crop_and_fertilizer_western_maharashtra_filled_humidity.csv
uploaded = files.upload()
df_original = pd.read_csv('Crop_recommendation.csv')
df_maha = pd.read_csv('crop_and_fertilizer_western_maharashtra_filled_humidity.csv')

# Mapping for renaming Maharashtra columns
maha_col_map = {
    'Nitrogen': 'N',
    'Phosphorus': 'P',
    'Potassium': 'K',
    'Temperature': 'temperature',
    'humidity': 'humidity',
    'pH': 'ph',
    'Rainfall': 'rainfall',
    'Crop': 'label'
}

# Select needed columns and rename
maha_keep = list(maha_col_map.keys())
df_maha_filtered = df_maha[maha_keep].rename(columns=maha_col_map)

# Reorder columns to match original
final_order = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']
df_maha_filtered = df_maha_filtered[final_order]
df_original = df_original[final_order]

# Merge the datasets
df_merged = pd.concat([df_original, df_maha_filtered], ignore_index=True)

# Optional: Save the merged file
df_merged.to_csv('merged_crop_recommendation_maharashtra.csv', index=False)
files.download('merged_crop_recommendation_maharashtra.csv')

import pandas as pd

# Load the merged dataset
df = pd.read_csv('Crop_recommendation.csv')

# Display all unique crop names in the 'label' column
print("Unique crops in crop_recommendation dataset:")
print(df['label'].unique())

# Load the merged dataset
df = pd.read_csv('crop_and_fertilizer_western_maharashtra_filled_humidity.csv')

# Display all unique crop names in the 'label' column
print("Unique crops incrop_and_fertilizer_western_maharashtra_filled_humidity dataset:")
print(df['Crop'].unique())

# Load the merged dataset
df = pd.read_csv('merged_crop_recommendation_maharashtra.csv')

# Display all unique crop names in the 'label' column
print("Unique crops in merged_crop_recommendation_maharashtra dataset:")
print(df['label'].unique())

import pandas as pd

# Load the merged dataset
df = pd.read_csv('merged_crop_recommendation_maharashtra.csv')

# Standardize all crop labels to lowercase, strip whitespace
df['label'] = df['label'].str.lower().str.strip()

# Create mapping for synonyms and local synonyms
synonym_map = {
    'moong': 'mungbean',
    'mung bean': 'mungbean',
    'mungbean': 'mungbean',
    'chana': 'chickpea',
    'gram': 'chickpea',
    'pigeonpea': 'pigeonpeas',
    'tur': 'pigeonpeas',
    'arhar': 'pigeonpeas',
    'urad': 'blackgram',
    'black gram': 'blackgram',
    'blackgram': 'blackgram',
    'masoor': 'lentil',
    'lentil': 'lentil',
    'cotton': 'cotton',
    'mothbeans': 'mothbeans',
    'soybean': 'soybean',
    'groundnut': 'groundnut',
    'rice': 'rice',
    'wheat': 'wheat',
    'jowar': 'jowar',
    'bajra': 'bajra',
    'ragi': 'ragi',
    'sugarcane': 'sugarcane',
    'banana': 'banana',
    'mango': 'mango',
    'pomegranate': 'pomegranate',
    'orange': 'orange',
    'papaya': 'papaya',
    'grapes': 'grapes',
    # Add any additional synonym as necessary
}

# NOTE: To ensure full mapping, for crop names not in the map (e.g. 'coffee', 'apple'), keep as is.
df['label'] = df['label'].replace(synonym_map)

# Optional: Show all unique standardized crop labels
print("Standardized unique crop labels:\n", sorted(df['label'].unique()))

# Save the cleaned and standardized dataset
df.to_csv('cleaned_merged_crop_recommendation_maharashtra.csv', index=False)
print("Cleaned and standardized dataset saved as 'cleaned_merged_crop_recommendation_maharashtra.csv'")



# Import required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Step 1: Upload the cleaned dataset
from google.colab import files
uploaded = files.upload()  # Upload 'cleaned_merged_crop_recommendation_maharashtra.csv'

# Step 2: Load the dataset
df = pd.read_csv('cleaned_merged_crop_recommendation_maharashtra.csv')
print("Dataset shape:", df.shape)
print("Dataset columns:", df.columns.tolist())
print("\nFirst 5 rows:")
print(df.head())

# Step 3: Prepare features and target
X = df.drop('label', axis=1)  # Features: N, P, K, temperature, humidity, ph, rainfall
y = df['label']               # Target: crop labels

print(f"\nFeatures: {X.columns.tolist()}")
print(f"Target classes: {sorted(y.unique())}")
print(f"Number of unique crops: {y.nunique()}")

# Step 4: Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training set size: {X_train.shape[0]}")
print(f"Test set size: {X_test.shape[0]}")

# Step 5: Train the Random Forest model
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Step 6: Evaluate the model
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Step 7: Feature importance
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)

# Step 8: Crop Recommendation Function
def recommend_crops(input_features, model, top_n=3):
    """
    Recommend top N crops based on input soil and weather conditions

    Parameters:
    input_features (dict): Dictionary with keys ['N','P','K','temperature','humidity','ph','rainfall']
    model: Trained RandomForest model
    top_n (int): Number of top recommendations to return

    Returns:
    list: List of tuples (crop_name, probability)
    """
    input_df = pd.DataFrame([input_features])
    probabilities = model.predict_proba(input_df)[0]
    crop_indexes = np.argsort(probabilities)[::-1][:top_n]
    all_labels = model.classes_
    recommendations = [(all_labels[i], probabilities[i]) for i in crop_indexes]
    return recommendations

# Step 9: Example Usage - Maharashtra Conditions
example_features = {
    'N': 90,        # Nitrogen
    'P': 42,        # Phosphorus
    'K': 43,        # Potassium
    'temperature': 24.1,  # Temperature in Celsius
    'humidity': 75.3,     # Humidity percentage
    'ph': 6.5,      # Soil pH
    'rainfall': 165.0     # Rainfall in mm
}

# Get recommendations
top_crops = recommend_crops(example_features, rf)
print("\n" + "="*50)
print("CROP RECOMMENDATION RESULTS")
print("="*50)
print("Input Conditions:")
for key, value in example_features.items():
    print(f"  {key}: {value}")

print(f"\nTop {len(top_crops)} Recommended Crops:")
for i, (crop, prob) in enumerate(top_crops, 1):
    print(f"  {i}. {crop.title()}: {prob:.3f} ({prob*100:.1f}%)")

# Step 10: Interactive Recommendation Function
def get_user_recommendations():
    """Interactive function to get user input and provide recommendations"""
    print("\n" + "="*50)
    print("MAHARASHTRA CROP ADVISORY SYSTEM")
    print("="*50)
    print("Enter your soil and weather conditions:")

    try:
        user_input = {
            'N': float(input("Nitrogen (N) content: ")),
            'P': float(input("Phosphorus (P) content: ")),
            'K': float(input("Potassium (K) content: ")),
            'temperature': float(input("Temperature (Â°C): ")),
            'humidity': float(input("Humidity (%): ")),
            'ph': float(input("Soil pH: ")),
            'rainfall': float(input("Rainfall (mm): "))
        }

        recommendations = recommend_crops(user_input, rf)

        print(f"\nBased on your conditions, here are the top {len(recommendations)} recommended crops:")
        for i, (crop, prob) in enumerate(recommendations, 1):
            print(f"  {i}. {crop.title()}: {prob*100:.1f}% suitability")

    except ValueError:
        print("Please enter valid numeric values!")

# Step 11: Save the trained model
joblib.dump(rf, 'maharashtra_crop_recommendation_model.pkl')
print("\nModel saved as 'maharashtra_crop_recommendation_model.pkl'")

# Step 12: Function to load and use saved model
def load_model_and_predict(input_features, model_path='maharashtra_crop_recommendation_model.pkl'):
    """Load saved model and make predictions"""
    loaded_model = joblib.load(model_path)
    return recommend_crops(input_features, loaded_model)

print("\n" + "="*50)
print("SETUP COMPLETE!")
print("="*50)
print("You can now use:")
print("1. recommend_crops(input_features, rf) - for direct recommendations")
print("2. get_user_recommendations() - for interactive input")
print("3. Load saved model using joblib.load() for future use")



