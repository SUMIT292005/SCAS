# -*- coding: utf-8 -*-
"""final_cotton.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aq7jeNpbOmgdWmrE_-wjdt-42o3beo3c
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# 1. Unzip the dataset
zip_path = "/content/drive/MyDrive/Dataset/Cotton_Disease_Dataset_Balanced.zip"
extract_path = "/content/Cotton_Disease_Dataset_Balanced"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset extracted!")

# 2. Browse the folder structure
for root, dirs, files in os.walk(extract_path):
    level = root.replace(extract_path, '').count(os.sep)
    indent = ' ' * 4 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 4 * (level + 1)
    for f in files[:5]:  # show only first 5 files per folder
        print(f"{subindent}{f}")

# 3. Count images per class
from collections import defaultdict

image_counts = defaultdict(int)

for root, dirs, files in os.walk(extract_path):
    class_name = os.path.basename(root)
    image_counts[class_name] += len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])

print("\nðŸ“Š Images per class:")
for cls, count in image_counts.items():
    print(f"{cls}: {count}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.preprocessing import image
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

# ==============================
# Dataset Paths
# ==============================
train_dir = "Cotton_Disease_Dataset_Balanced"

# ==============================
# Data Generators with Augmentation
# ==============================
datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.2,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True,
    brightness_range=[0.7, 1.3],
    channel_shift_range=30
)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),  # EfficientNetB3 input size
    batch_size=32,
    class_mode="categorical",
    subset="training",
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode="categorical",
    subset="validation",
    shuffle=False   # important for confusion matrix
)

# ==============================
# Compute Class Weights
# ==============================
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weights = dict(enumerate(class_weights))
print("Class Weights:", class_weights)

# ==============================
# Build EfficientNetB3 Model
# ==============================
base_model = EfficientNetB3(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # freeze base model initially

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
predictions = Dense(train_generator.num_classes, activation="softmax")(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(learning_rate=0.0005), loss="categorical_crossentropy", metrics=["accuracy"])

# ==============================
# Callbacks
# ==============================
lr_reduction = ReduceLROnPlateau(monitor="val_loss", factor=0.3, patience=3, verbose=1)
early_stop = EarlyStopping(monitor="val_loss", patience=7, restore_best_weights=True)

# ==============================
# Step 1: Train Top Layers
# ==============================
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=25,
    callbacks=[lr_reduction, early_stop],
    class_weight=class_weights,
    verbose=1
)

# ==============================
# Step 2: Fine-tune Entire Model
# ==============================
base_model.trainable = True
model.compile(optimizer=Adam(learning_rate=1e-5), loss="categorical_crossentropy", metrics=["accuracy"])

history_fine = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=30,
    callbacks=[lr_reduction, early_stop],
    class_weight=class_weights,
    verbose=1
)

# ==============================
# Save Model
# ==============================
model.save("updated_cotton_disease_efficientnetb3.h5")

# ==============================
# Plot Training Curves
# ==============================
plt.plot(history_fine.history["accuracy"], label="train_acc")
plt.plot(history_fine.history["val_accuracy"], label="val_acc")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# ==============================
# Evaluate & Confusion Matrix
# ==============================
# Predict on validation set
Y_pred = model.predict(val_generator)
y_pred = np.argmax(Y_pred, axis=1)

# Confusion matrix
cm = confusion_matrix(val_generator.classes, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=val_generator.class_indices.keys())
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.show()

# Classification report
print("Classification Report:\n")
print(classification_report(val_generator.classes, y_pred, target_names=val_generator.class_indices.keys()))

# ==============================
# Test Single Image Prediction
# ==============================
def predict_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    preds = model.predict(img_array)
    class_labels = list(train_generator.class_indices.keys())
    predicted_class = class_labels[np.argmax(preds)]
    confidence = np.max(preds) * 100

    print(f"Prediction: {predicted_class} ({confidence:.2f}%)")
    return predicted_class, confidence

# Example usage:
# predict_image("Cotton_Disease_Dataset_Balanced/Target spot/rotate_zoompil_sharpness_28.jpg")

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# ==============================
# Evaluate Model with Confusion Matrix & Report
# ==============================

# Get ground truth labels and predictions
val_generator.reset()
Y_pred = model.predict(val_generator, verbose=1)
y_pred = np.argmax(Y_pred, axis=1)
y_true = val_generator.classes

# Class labels
class_labels = list(val_generator.class_indices.keys())

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_labels))

# ==============================
# Evaluate Model on Validation Set
# ==============================
val_loss, val_acc = model.evaluate(val_generator, verbose=1)

print("âœ… Final Validation Accuracy: {:.2f}%".format(val_acc * 100))
print("âœ… Final Validation Loss: {:.4f}".format(val_loss))

import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model

# ==============================
# Load the saved model
# ==============================
model = load_model("/content/updated_cotton_disease_efficientnetb3.h5")

# ==============================
# Test on a single image
# ==============================
img_path = "/content/Cotton_Disease_Dataset_Balanced/Powdery mildew/10.jpg"   # change to your image path
img_size = 224   # same size used during training

# Load and preprocess image
img = image.load_img(img_path, target_size=(img_size, img_size))
img_array = image.img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)  # add batch dimension

# Predict
pred = model.predict(img_array)
class_index = np.argmax(pred[0])   # get index of highest probability
confidence = np.max(pred[0]) * 100

# Map class index to label
class_labels = list(train_generator.class_indices.keys())  # same labels from training
predicted_class = class_labels[class_index]

print(f"âœ… Predicted Class: {predicted_class}")
print(f"âœ… Confidence: {confidence:.2f}%")















